<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      /* Sans: Lato, Fira Sans, Fira Sans Condensed;  Serif Sans: Merriweather, Lora, Galdeano*/
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 16px
    }
    
    strong {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    heading {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 24px;
    }
    
    papertitle {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 700
    }
    
    name {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 36px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/ico" href="favicon.ico">
  <title>Xuejian Rong</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href="https://fonts.googleapis.com/css?family=Galdeano" rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Xuejian Rong</name>
              </p>
              <p>I am a researcher at <a href="http://media-lab.ccny.cuny.edu">Media Lab</a> of <a href="http://www.ccny.cuny.edu">The City College</a>, <a href="http://cuny.edu">City University of New York</a>, where I work in the intersection of Deep Learning, Computer Vision, and Image Processing. I am finishing a Ph.D. advised by Prof. <a href="https://scholar.google.com/citations?user=aAWeB4wAAAAJ&hl=en">Yingli Tian</a>. Currently my research interests mainly focus on inference and learning for scene text detection and recognition in the wild, and visual-linguistic understanding on scene text Images.
              </p>
              <p>
                My thesis proposal is entitled "<em>Deep Features for Context-aware Text Extraction</em>" and the slides are available <a href="https://www.dropbox.com/s/s4dlcuqwt3vml3x/2nd.Exam.Xuejian.Rong.4.28.17.slides.pdf?dl=0">here</a>. I interned at <a href="">Siemens Corporate Research</a> and worked on the visual representation learning for novel view synthesis. I obtained the B.E. degree from <a href="http://iao.nuaa.edu.cn">Nanjing University of Aeronautics and Astronautics</a> at 2013.
              </p>
              <p align=center>
                <a href="mailto:xrong@ccny.cuny.edu">Email</a> &nbsp/&nbsp
                <a href="resume.pdf">Resume</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=lhAJNwkAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="http://www.linkedin.com/in/xuejianrong/"> LinkedIn </a>
              </p>
            </td>
            <td width="33%">
              <img src="avatar_circle.png">
            </td>
          </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research (in maintenance)</heading>
              <p>
                <!-- I'm interested in computer vision, machine learning, statistics, optimization, image processing, virtual reality, and computational photography. Much of my research is about inferring the physical world (shape, depth, motion, paint, light, colors, etc) from images. I have also worked in astronomy and biology. Representative papers are <span class="highlight">highlighted</span>. -->
              </p>
            </td>
          </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">



          <tr>
            <td width="25%"><img src="images/cvpr17.jpg" alt="cvpr17" width="160" height="120" style="border-style: none">
            <td width="75%" valign="top">
              <p>
                <a href="http://xrong.org/publications/cvpr17.pdf" id="cvpr17">
                  <papertitle>Unambiguous Text Localization and Retrieval for Cluttered Scenes</papertitle>
                </a>
                <br>
                <strong>Xuejian Rong</strong>, <a href="http://yichucai.net">Chucai Yi</a>, <a href="https://scholar.google.com/citations?user=aAWeB4wAAAAJ&hl=en">Yingli Tian</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2017 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
                <br>
                <a href="">code</a> / <a
                  href="">data</a>
              </p>
              <p>
                Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D
                sensor.
                <br>
              </p>
            </td>
          </tr>

          <tr>
            <td width="25%"><img src="images/tcsvt17.jpg" alt="tcsvt17" width="160" height="120" style="border-style: none">
            <td width="75%" valign="top">
              <p>
                <a href="http://xrong.org/publications/tcsvt16.pdf" id="tcsvt17">
                  <papertitle>Evaluation of Low-Level Features for Real-World Surveillance Event Detection</papertitle>
                </a>
                <br>
                <a href="http://yangxian.info/">Yang Xian</a>, <strong>Xuejian Rong</strong>, <a href="http://xiaodongyang.org/">Xiaodong Yang</a>, <a
                  href="https://scholar.google.com/citations?user=aAWeB4wAAAAJ&hl=en">Yingli Tian</a>
                <br>
                <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</em>, 2017
                <br>
                <a href="">code</a> / <a
                  href="">data</a>
              </p>
              <p>
                Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D
                sensor.
                <br>
              </p>
            </td>
          </tr>

        <tr>
            <td width="25%"><img src="images/cyber17.jpg" alt="cyber17" width="160" height="120" style="border-style: none">
            <td width="75%" valign="top">
              <p>
                <a href="http://xrong.org/publications/cyber17.pdf" id="cyber17">
                  <papertitle>Assistive Indoor Navigation for the Visually Impaired in Multi-Floor Environments</papertitle>
                </a>
                <br>
                J. Pablo Munoz, <a href=https://robotlee2002.github.io/>Bing Li</a>, <strong>Xuejian Rong</strong>, <a href="https://ccny-ros-pkg.github.io/prof/jxiao.html">Jizhong Xiao</a>, <a
                  href="https://scholar.google.com/citations?user=aAWeB4wAAAAJ&hl=en">Yingli Tian</a>, and Aris Arditi
                <br>
                <em>IEEE International Conference on Cyber Technology (CYBER)</em> 2017
                <br>
                <a href="">code</a> / <a
                  href="">data</a>
              </p>
              <p>
                Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D
                sensor.
                <br>
              </p>
            </td>
          </tr>


        <tr>
          <td width="25%"><img src="images/isvc16.jpg" alt="isvc2016" width="160" height="120" style="border-style: none">
          <td width="75%" valign="top">
            <p>
              <a href="http://xrong.org/publications/isvc16.pdf" id="isvc16">
                <papertitle>Guided Text Spotting for Assistive Blind Navigation in Unfamiliar Environments.</papertitle>
              </a>
              <br>
              <strong>Xuejian Rong</strong>, <a href=https://robotlee2002.github.io/>Bing Li</a>, <a href="https://ccny-ros-pkg.github.io/prof/jxiao.html">Jizhong
                Xiao</a>, Aris
              Arditi, and <a href="https://scholar.google.com/citations?user=aAWeB4wAAAAJ&hl=en">Yingli Tian</a>
                <br>
                <em>The 12th International Symposium on Visual Computing (ISVC)</em> 2017 &nbsp <font color=#FF8080><strong>(Oral)</strong></font>
                <br>
                <a href="">code</a> / <a href="">data</a>
            </p>
            <p>
              Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D
              sensor.
              <br>
            </p>
          </td>
        </tr>


        <tr>
          <td width="25%"><img src="images/dsp16.jpg" alt="dsp16" width="160" height="120" style="border-style: none">
          <td width="75%" valign="top">
            <p>
              <a href="http://xrong.org/publications/dsp16.pdf" id="dsp16">
                <papertitle>Adaptive Shrinkage Cascades for Blind Image Deconvolution.</papertitle>
              </a>
              <br>
              <strong>Xuejian Rong</strong> and <a href="https://scholar.google.com/citations?user=aAWeB4wAAAAJ&hl=en">Yingli Tian</a>
                <br>
                <em>IEEE International Conference on Digital Signal Processing (DSP)</em> 2016 &nbsp <font color=#FF8080><strong>(Oral)</strong></font>
                <br>
                <a href="">code</a> / <a href="">data</a>
            </p>
            <p>
              Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D
              sensor.
              <br>
            </p>
          </td>
        </tr>


        <tr>
          <td width="25%"><img src="images/cvrsuad16.jpg" alt="cvrsuad16" width="160" height="120" style="border-style: none">
          <td width="75%" valign="top">
            <p>
              <a href="http://xrong.org/publications/cvrsuad16.pdf" id="cvrsuad16">
                <papertitle>Recognizing Text-based Traffic Guide Panels with Cascaded Localization Network</papertitle>
              </a>
              <br>
              <strong>Xuejian Rong</strong>, and <a href="https://scholar.google.com/citations?user=aAWeB4wAAAAJ&hl=en">Yingli
                Tian</a>
              <br>
              <em>ECCV Workshop on Computer Vision for Road Scene Understanding and Autonomous Driving (CVRSUAD)</em> 2016
              <br>
              <a href="">code</a> / <a href="">data</a>
            </p>
            <p>
              Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D
              sensor.
              <br>
            </p>
          </td>
        </tr>


        <tr>
          <td width="25%"><img src="images/icmr16.jpg" alt="icmr16" width="160" height="120" style="border-style: none">
          <td width="75%" valign="top">
            <p>
              <a href="http://xrong.org/publications/icmr16.pdf" id="icmr16">
                <papertitle>Region Trajectories for Video Semantic Concept Detection</papertitle>
              </a>
              <br>
              Yuancheng Ye, <strong>Xuejian Rong</strong>, and <a href="https://scholar.google.com/citations?user=aAWeB4wAAAAJ&hl=en">Yingli
                Tian</a>
              <br>
              <em>ACM International Conference on Multimedia Retrieval (ICMR)</em> 2016
              <br>
              <a href="">code</a> / <a href="">data</a>
            </p>
            <p>
              Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D
              sensor.
              <br>
            </p>
          </td>
        </tr>

        <tr>
          <td width="25%"><img src="images/acvr17.jpg" alt="acvr17" width="160" height="120" style="border-style: none">
          <td width="75%" valign="top">
            <p>
              <a href="http://xrong.org/publications/acvr17.pdf" id="acvr17">
                <papertitle>Assistive Indoor Navigation for the Visually Impaired in Multi-Floor Environments</papertitle>
              </a>
              <br>
              J. Pablo Munoz, <a href=https://robotlee2002.github.io/>Bing Li</a>, <strong>Xuejian Rong</strong>, <a href="https://ccny-ros-pkg.github.io/prof/jxiao.html">Jizhong
                  Xiao</a>, <a href="https://scholar.google.com/citations?user=aAWeB4wAAAAJ&hl=en">Yingli Tian</a>, and Aris
                Arditi
                <br>
                <em>IEEE International Conference on Cyber Technology (CYBER)</em> 2017
                <br>
                <a href="">code</a> / <a href="">data</a>
            </p>
            <p>
              Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D
              sensor.
              <br>
            </p>
          </td>
        </tr>









        <!-- </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Course Projects</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="images/prl.jpg" alt="prl" width="160" height="160"></td>
            <td width="75%" valign="top">
              <p>
                <a href="https://drive.google.com/file/d/13rVuJpcytRdLYCnKpq46g7B7IzSrPQ2P/view?usp=sharing">
                  <papertitle>Title</papertitle>
                </a>
                <br>
                <strong>Xuejian Rong</strong>, <a href="http://www.eecs.berkeley.edu/~dsg/">Dave Golland</a>, <a href="http://www.cs.berkeley.edu/~nickjhay/">Nicholas J. Hay</a>, 2009
                <p>
                  <br> Markov Decision Problems which lie in a low-dimensional latent space can be decomposed, allowing modified RL algorithms to run orders of magnitude faster in parallel.
                </p>
              </p>
            </td>
          </tr>
        </table> -->
        
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="images/pacman.jpg" alt="pacman" width="160" height="160"></td>
            <td width="75%" valign="center">
              <p>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">
                  <papertitle>CS188 - Fall 2010 (GSI)</papertitle>
                </a>
                <br>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">
                  <papertitle>CS188 - Spring 2011 (GSI)</papertitle>
                </a>
                <br>
              </p>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
            </td>
          </tr>
        </table>
        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr>
  </table>
</body>

</html>
